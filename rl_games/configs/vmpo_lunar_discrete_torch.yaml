params:  
  algo:
    name: vmpo_discrete

  model:
    name: discrete_a2c

  network:
    name: actor_critic
    separate: True
    space:
      discrete:
    mlp:
      units: [64,64]
      activation: relu
      initializer:
          name: default


  config:
      reward_shaper:
        scale_value: 0.1
      normalize_advantage: False
      gamma: 0.99
      tau: 0.95

      learning_rate: 5e-4
      name: vmpo_lunar_discrete
      score_to_win: 300

      grad_norm: 10
      entropy_coef: 0.00
      truncate_grads: True
      env_name:  LunarLander-v2
      ppo: true
      e_clip: 0.2
      clip_value: True
      num_actors: 16
      horizon_length: 256
      minibatch_size: 1024
      mini_epochs: 4
      critic_coef: 1
      lr_schedule:  None
      kl_threshold: 0.008
      schedule_type: standard
      normalize_input: False
      normalize_value: True
      seq_length: 4
      bounds_loss_coef: 0
      max_epochs: 1000

      eta: 1.0
      alpha: 0.1
      eps_eta: 0.02
      eps_alpha: 0.1
      player:
        render: True
