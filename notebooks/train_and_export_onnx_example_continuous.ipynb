{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f833523c",
   "metadata": {},
   "source": [
    "**This is example of how to trace model with jit and export it to the onnx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d832d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "from rl_games.torch_runner import Runner\n",
    "import ray\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf09dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.12', ray_version='1.12.0', ray_commit='f18fc31c7562990955556899090f8e8656b48d2d', address_info={'node_ip_address': '10.2.168.57', 'raylet_ip_address': '10.2.168.57', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-09-16_13-07-38_643208_1200015/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-09-16_13-07-38_643208_1200015/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-09-16_13-07-38_643208_1200015', 'metrics_export_port': 58850, 'gcs_address': '10.2.168.57:47337', 'address': '10.2.168.57:47337', 'node_id': 'a41e8ed5dcebcaabbb00fcc7b042adca6e16353a1c7cd5fe7272e7a3'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(object_store_memory=1024*1024*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8682b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = '../rl_games/configs/ppo_pendulum_torch.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91c090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.seed = 1663358860\n",
      "Started to train\n",
      "Exact experiment name requested from command line: pendulum_onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayWorker pid=1200387)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200387)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200383)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200383)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200388)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200388)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200389)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200389)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200386)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200386)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200382)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200382)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200385)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200385)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200384)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200384)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200475)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200475)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200527)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200527)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200537)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200537)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200487)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200487)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200573)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200573)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200513)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200513)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200585)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200585)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200593)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1200593)\u001b[0m   deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current training device: cuda:0\n",
      "build mlp: 3\n",
      "build mlp: 3\n",
      "RunningMeanStd:  (3,)\n",
      "fps step: 2401 fps step and policy inference: 1051 fps total: 1028 epoch: 1/200\n",
      "fps step: 2456 fps step and policy inference: 1879 fps total: 1799 epoch: 2/200\n",
      "fps step: 2571 fps step and policy inference: 1950 fps total: 1893 epoch: 3/200\n",
      "fps step: 2325 fps step and policy inference: 1781 fps total: 1702 epoch: 4/200\n",
      "fps step: 2388 fps step and policy inference: 1814 fps total: 1756 epoch: 5/200\n",
      "fps step: 2507 fps step and policy inference: 1899 fps total: 1820 epoch: 6/200\n",
      "fps step: 2603 fps step and policy inference: 1983 fps total: 1923 epoch: 7/200\n",
      "fps step: 2594 fps step and policy inference: 1951 fps total: 1872 epoch: 8/200\n",
      "fps step: 2589 fps step and policy inference: 1968 fps total: 1903 epoch: 9/200\n",
      "fps step: 2595 fps step and policy inference: 1962 fps total: 1879 epoch: 10/200\n",
      "fps step: 2635 fps step and policy inference: 1989 fps total: 1927 epoch: 11/200\n",
      "fps step: 2641 fps step and policy inference: 1999 fps total: 1915 epoch: 12/200\n",
      "fps step: 2568 fps step and policy inference: 1939 fps total: 1857 epoch: 13/200\n",
      "fps step: 2324 fps step and policy inference: 1754 fps total: 1686 epoch: 14/200\n",
      "fps step: 2343 fps step and policy inference: 1791 fps total: 1723 epoch: 15/200\n",
      "fps step: 2523 fps step and policy inference: 1913 fps total: 1845 epoch: 16/200\n",
      "fps step: 2419 fps step and policy inference: 1854 fps total: 1779 epoch: 17/200\n",
      "fps step: 2602 fps step and policy inference: 1973 fps total: 1912 epoch: 18/200\n",
      "fps step: 2495 fps step and policy inference: 1895 fps total: 1816 epoch: 19/200\n",
      "fps step: 2490 fps step and policy inference: 1895 fps total: 1841 epoch: 20/200\n",
      "fps step: 2542 fps step and policy inference: 1928 fps total: 1844 epoch: 21/200\n",
      "fps step: 2652 fps step and policy inference: 1991 fps total: 1919 epoch: 22/200\n",
      "fps step: 2520 fps step and policy inference: 1893 fps total: 1818 epoch: 23/200\n",
      "fps step: 2611 fps step and policy inference: 1976 fps total: 1917 epoch: 24/200\n",
      "fps step: 2526 fps step and policy inference: 1913 fps total: 1830 epoch: 25/200\n",
      "fps step: 2652 fps step and policy inference: 1982 fps total: 1911 epoch: 26/200\n",
      "fps step: 2568 fps step and policy inference: 1938 fps total: 1864 epoch: 27/200\n",
      "fps step: 2523 fps step and policy inference: 1912 fps total: 1835 epoch: 28/200\n",
      "fps step: 2593 fps step and policy inference: 1955 fps total: 1892 epoch: 29/200\n",
      "fps step: 2628 fps step and policy inference: 2000 fps total: 1920 epoch: 30/200\n",
      "fps step: 2555 fps step and policy inference: 1943 fps total: 1865 epoch: 31/200\n",
      "fps step: 2681 fps step and policy inference: 2018 fps total: 1932 epoch: 32/200\n",
      "fps step: 2574 fps step and policy inference: 1957 fps total: 1875 epoch: 33/200\n",
      "fps step: 2607 fps step and policy inference: 1969 fps total: 1896 epoch: 34/200\n",
      "fps step: 2547 fps step and policy inference: 1934 fps total: 1848 epoch: 35/200\n",
      "fps step: 2491 fps step and policy inference: 1907 fps total: 1845 epoch: 36/200\n",
      "fps step: 2502 fps step and policy inference: 1883 fps total: 1806 epoch: 37/200\n",
      "fps step: 2409 fps step and policy inference: 1818 fps total: 1742 epoch: 38/200\n",
      "fps step: 2411 fps step and policy inference: 1829 fps total: 1753 epoch: 39/200\n",
      "fps step: 2605 fps step and policy inference: 1967 fps total: 1886 epoch: 40/200\n",
      "fps step: 2492 fps step and policy inference: 1897 fps total: 1823 epoch: 41/200\n",
      "fps step: 2545 fps step and policy inference: 1918 fps total: 1849 epoch: 42/200\n",
      "fps step: 2502 fps step and policy inference: 1902 fps total: 1824 epoch: 43/200\n",
      "fps step: 2579 fps step and policy inference: 1936 fps total: 1845 epoch: 44/200\n",
      "fps step: 2340 fps step and policy inference: 1778 fps total: 1719 epoch: 45/200\n",
      "fps step: 2433 fps step and policy inference: 1832 fps total: 1753 epoch: 46/200\n",
      "fps step: 2442 fps step and policy inference: 1865 fps total: 1809 epoch: 47/200\n",
      "fps step: 2543 fps step and policy inference: 1934 fps total: 1851 epoch: 48/200\n",
      "fps step: 2601 fps step and policy inference: 1979 fps total: 1909 epoch: 49/200\n",
      "fps step: 2583 fps step and policy inference: 1947 fps total: 1864 epoch: 50/200\n",
      "fps step: 2493 fps step and policy inference: 1899 fps total: 1844 epoch: 51/200\n",
      "fps step: 2557 fps step and policy inference: 1927 fps total: 1841 epoch: 52/200\n",
      "fps step: 2561 fps step and policy inference: 1942 fps total: 1872 epoch: 53/200\n",
      "fps step: 2588 fps step and policy inference: 1945 fps total: 1865 epoch: 54/200\n",
      "fps step: 2450 fps step and policy inference: 1863 fps total: 1799 epoch: 55/200\n",
      "fps step: 2438 fps step and policy inference: 1865 fps total: 1792 epoch: 56/200\n",
      "fps step: 2439 fps step and policy inference: 1840 fps total: 1762 epoch: 57/200\n",
      "fps step: 2457 fps step and policy inference: 1866 fps total: 1787 epoch: 58/200\n",
      "fps step: 2451 fps step and policy inference: 1850 fps total: 1789 epoch: 59/200\n",
      "fps step: 2481 fps step and policy inference: 1885 fps total: 1816 epoch: 60/200\n",
      "fps step: 2434 fps step and policy inference: 1834 fps total: 1776 epoch: 61/200\n",
      "fps step: 2478 fps step and policy inference: 1881 fps total: 1803 epoch: 62/200\n",
      "fps step: 2547 fps step and policy inference: 1922 fps total: 1852 epoch: 63/200\n",
      "fps step: 2353 fps step and policy inference: 1792 fps total: 1721 epoch: 64/200\n",
      "fps step: 2529 fps step and policy inference: 1913 fps total: 1855 epoch: 65/200\n",
      "fps step: 2502 fps step and policy inference: 1905 fps total: 1828 epoch: 66/200\n",
      "fps step: 2935 fps step and policy inference: 2253 fps total: 2179 epoch: 67/200\n",
      "fps step: 2517 fps step and policy inference: 1991 fps total: 1927 epoch: 68/200\n",
      "fps step: 2913 fps step and policy inference: 2264 fps total: 2196 epoch: 69/200\n",
      "fps step: 3318 fps step and policy inference: 2545 fps total: 2455 epoch: 70/200\n",
      "fps step: 3233 fps step and policy inference: 2479 fps total: 2394 epoch: 71/200\n",
      "fps step: 3246 fps step and policy inference: 2492 fps total: 2400 epoch: 72/200\n",
      "fps step: 3312 fps step and policy inference: 2552 fps total: 2463 epoch: 73/200\n",
      "fps step: 3328 fps step and policy inference: 2557 fps total: 2469 epoch: 74/200\n",
      "fps step: 3344 fps step and policy inference: 2566 fps total: 2468 epoch: 75/200\n",
      "fps step: 3285 fps step and policy inference: 2499 fps total: 2409 epoch: 76/200\n",
      "fps step: 3307 fps step and policy inference: 2520 fps total: 2435 epoch: 77/200\n",
      "fps step: 3244 fps step and policy inference: 2495 fps total: 2413 epoch: 78/200\n",
      "fps step: 3245 fps step and policy inference: 2519 fps total: 2434 epoch: 79/200\n",
      "fps step: 3370 fps step and policy inference: 2602 fps total: 2513 epoch: 80/200\n",
      "fps step: 3390 fps step and policy inference: 2610 fps total: 2519 epoch: 81/200\n",
      "fps step: 3395 fps step and policy inference: 2612 fps total: 2523 epoch: 82/200\n",
      "fps step: 3445 fps step and policy inference: 2638 fps total: 2543 epoch: 83/200\n",
      "fps step: 3357 fps step and policy inference: 2578 fps total: 2489 epoch: 84/200\n",
      "fps step: 3423 fps step and policy inference: 2623 fps total: 2522 epoch: 85/200\n",
      "fps step: 3377 fps step and policy inference: 2595 fps total: 2505 epoch: 86/200\n",
      "fps step: 3230 fps step and policy inference: 2498 fps total: 2411 epoch: 87/200\n",
      "fps step: 3403 fps step and policy inference: 2604 fps total: 2511 epoch: 88/200\n",
      "fps step: 3409 fps step and policy inference: 2618 fps total: 2519 epoch: 89/200\n",
      "fps step: 3260 fps step and policy inference: 2522 fps total: 2434 epoch: 90/200\n",
      "fps step: 3372 fps step and policy inference: 2598 fps total: 2497 epoch: 91/200\n",
      "fps step: 3045 fps step and policy inference: 2356 fps total: 2279 epoch: 92/200\n",
      "fps step: 3047 fps step and policy inference: 2351 fps total: 2272 epoch: 93/200\n",
      "fps step: 3164 fps step and policy inference: 2448 fps total: 2367 epoch: 94/200\n",
      "fps step: 3188 fps step and policy inference: 2463 fps total: 2371 epoch: 95/200\n",
      "fps step: 3103 fps step and policy inference: 2405 fps total: 2324 epoch: 96/200\n",
      "fps step: 3324 fps step and policy inference: 2570 fps total: 2476 epoch: 97/200\n",
      "fps step: 3229 fps step and policy inference: 2502 fps total: 2415 epoch: 98/200\n",
      "fps step: 3229 fps step and policy inference: 2474 fps total: 2383 epoch: 99/200\n",
      "fps step: 3256 fps step and policy inference: 2513 fps total: 2421 epoch: 100/200\n",
      "saving next best rewards:  [-193.0487]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps step: 3321 fps step and policy inference: 2557 fps total: 2460 epoch: 101/200\n",
      "fps step: 3278 fps step and policy inference: 2522 fps total: 2439 epoch: 102/200\n",
      "fps step: 3325 fps step and policy inference: 2550 fps total: 2463 epoch: 103/200\n",
      "fps step: 3305 fps step and policy inference: 2532 fps total: 2439 epoch: 104/200\n",
      "fps step: 3345 fps step and policy inference: 2555 fps total: 2469 epoch: 105/200\n",
      "fps step: 3314 fps step and policy inference: 2534 fps total: 2447 epoch: 106/200\n",
      "fps step: 3338 fps step and policy inference: 2561 fps total: 2475 epoch: 107/200\n",
      "fps step: 3339 fps step and policy inference: 2572 fps total: 2484 epoch: 108/200\n",
      "fps step: 3335 fps step and policy inference: 2559 fps total: 2471 epoch: 109/200\n",
      "fps step: 3383 fps step and policy inference: 2591 fps total: 2499 epoch: 110/200\n",
      "fps step: 3354 fps step and policy inference: 2580 fps total: 2486 epoch: 111/200\n",
      "fps step: 3368 fps step and policy inference: 2603 fps total: 2501 epoch: 112/200\n",
      "fps step: 3223 fps step and policy inference: 2481 fps total: 2400 epoch: 113/200\n",
      "fps step: 3353 fps step and policy inference: 2570 fps total: 2437 epoch: 114/200\n",
      "fps step: 3366 fps step and policy inference: 2586 fps total: 2486 epoch: 115/200\n",
      "fps step: 3283 fps step and policy inference: 2528 fps total: 2444 epoch: 116/200\n",
      "fps step: 3399 fps step and policy inference: 2590 fps total: 2496 epoch: 117/200\n",
      "fps step: 3358 fps step and policy inference: 2584 fps total: 2490 epoch: 118/200\n",
      "fps step: 3150 fps step and policy inference: 2436 fps total: 2354 epoch: 119/200\n",
      "fps step: 3137 fps step and policy inference: 2400 fps total: 2319 epoch: 120/200\n",
      "fps step: 2894 fps step and policy inference: 2227 fps total: 2120 epoch: 121/200\n",
      "fps step: 3039 fps step and policy inference: 2350 fps total: 2273 epoch: 122/200\n",
      "fps step: 3315 fps step and policy inference: 2565 fps total: 2473 epoch: 123/200\n",
      "fps step: 2836 fps step and policy inference: 2189 fps total: 2123 epoch: 124/200\n",
      "fps step: 3146 fps step and policy inference: 2443 fps total: 2361 epoch: 125/200\n",
      "fps step: 3307 fps step and policy inference: 2534 fps total: 2432 epoch: 126/200\n",
      "fps step: 3160 fps step and policy inference: 2431 fps total: 2347 epoch: 127/200\n",
      "fps step: 3258 fps step and policy inference: 2506 fps total: 2419 epoch: 128/200\n",
      "fps step: 3154 fps step and policy inference: 2452 fps total: 2366 epoch: 129/200\n",
      "fps step: 2892 fps step and policy inference: 2251 fps total: 2153 epoch: 130/200\n",
      "fps step: 2945 fps step and policy inference: 2281 fps total: 2209 epoch: 131/200\n",
      "fps step: 3211 fps step and policy inference: 2476 fps total: 2390 epoch: 132/200\n",
      "fps step: 2606 fps step and policy inference: 2029 fps total: 1946 epoch: 133/200\n",
      "fps step: 3219 fps step and policy inference: 2473 fps total: 2392 epoch: 134/200\n",
      "fps step: 2520 fps step and policy inference: 2007 fps total: 1944 epoch: 135/200\n",
      "fps step: 2848 fps step and policy inference: 2204 fps total: 2135 epoch: 136/200\n",
      "fps step: 2717 fps step and policy inference: 2156 fps total: 2081 epoch: 137/200\n",
      "fps step: 3087 fps step and policy inference: 2401 fps total: 2320 epoch: 138/200\n",
      "fps step: 3155 fps step and policy inference: 2472 fps total: 2388 epoch: 139/200\n",
      "fps step: 3271 fps step and policy inference: 2520 fps total: 2424 epoch: 140/200\n",
      "fps step: 3203 fps step and policy inference: 2470 fps total: 2387 epoch: 141/200\n",
      "fps step: 3359 fps step and policy inference: 2584 fps total: 2493 epoch: 142/200\n",
      "fps step: 3312 fps step and policy inference: 2558 fps total: 2471 epoch: 143/200\n",
      "fps step: 3087 fps step and policy inference: 2390 fps total: 2310 epoch: 144/200\n",
      "fps step: 3144 fps step and policy inference: 2437 fps total: 2355 epoch: 145/200\n",
      "fps step: 3407 fps step and policy inference: 2623 fps total: 2517 epoch: 146/200\n",
      "fps step: 3305 fps step and policy inference: 2547 fps total: 2450 epoch: 147/200\n",
      "fps step: 3227 fps step and policy inference: 2483 fps total: 2395 epoch: 148/200\n",
      "fps step: 3143 fps step and policy inference: 2445 fps total: 2353 epoch: 149/200\n",
      "fps step: 3239 fps step and policy inference: 2518 fps total: 2430 epoch: 150/200\n",
      "fps step: 3347 fps step and policy inference: 2589 fps total: 2498 epoch: 151/200\n",
      "fps step: 3340 fps step and policy inference: 2564 fps total: 2474 epoch: 152/200\n",
      "fps step: 3391 fps step and policy inference: 2605 fps total: 2506 epoch: 153/200\n",
      "fps step: 3364 fps step and policy inference: 2598 fps total: 2502 epoch: 154/200\n",
      "fps step: 3215 fps step and policy inference: 2486 fps total: 2376 epoch: 155/200\n",
      "fps step: 3243 fps step and policy inference: 2510 fps total: 2414 epoch: 156/200\n",
      "fps step: 3395 fps step and policy inference: 2588 fps total: 2496 epoch: 157/200\n",
      "fps step: 3467 fps step and policy inference: 2645 fps total: 2542 epoch: 158/200\n",
      "fps step: 3358 fps step and policy inference: 2581 fps total: 2491 epoch: 159/200\n",
      "fps step: 3361 fps step and policy inference: 2572 fps total: 2481 epoch: 160/200\n",
      "fps step: 3310 fps step and policy inference: 2549 fps total: 2463 epoch: 161/200\n",
      "fps step: 3348 fps step and policy inference: 2577 fps total: 2480 epoch: 162/200\n",
      "fps step: 3342 fps step and policy inference: 2550 fps total: 2457 epoch: 163/200\n",
      "fps step: 3402 fps step and policy inference: 2609 fps total: 2520 epoch: 164/200\n",
      "fps step: 3385 fps step and policy inference: 2591 fps total: 2499 epoch: 165/200\n",
      "fps step: 3345 fps step and policy inference: 2581 fps total: 2487 epoch: 166/200\n",
      "fps step: 2983 fps step and policy inference: 2332 fps total: 2247 epoch: 167/200\n",
      "fps step: 3278 fps step and policy inference: 2525 fps total: 2440 epoch: 168/200\n",
      "fps step: 3378 fps step and policy inference: 2600 fps total: 2508 epoch: 169/200\n",
      "fps step: 3258 fps step and policy inference: 2504 fps total: 2417 epoch: 170/200\n",
      "fps step: 3345 fps step and policy inference: 2574 fps total: 2487 epoch: 171/200\n",
      "fps step: 3268 fps step and policy inference: 2522 fps total: 2437 epoch: 172/200\n",
      "fps step: 3271 fps step and policy inference: 2530 fps total: 2434 epoch: 173/200\n",
      "fps step: 3255 fps step and policy inference: 2505 fps total: 2420 epoch: 174/200\n",
      "fps step: 3305 fps step and policy inference: 2538 fps total: 2445 epoch: 175/200\n",
      "fps step: 3315 fps step and policy inference: 2552 fps total: 2457 epoch: 176/200\n",
      "fps step: 3186 fps step and policy inference: 2468 fps total: 2385 epoch: 177/200\n",
      "fps step: 3383 fps step and policy inference: 2603 fps total: 2510 epoch: 178/200\n",
      "fps step: 3038 fps step and policy inference: 2358 fps total: 2285 epoch: 179/200\n",
      "fps step: 3050 fps step and policy inference: 2368 fps total: 2288 epoch: 180/200\n",
      "fps step: 3257 fps step and policy inference: 2499 fps total: 2412 epoch: 181/200\n",
      "fps step: 3333 fps step and policy inference: 2577 fps total: 2484 epoch: 182/200\n",
      "fps step: 3348 fps step and policy inference: 2585 fps total: 2492 epoch: 183/200\n",
      "fps step: 3274 fps step and policy inference: 2510 fps total: 2424 epoch: 184/200\n",
      "fps step: 3375 fps step and policy inference: 2596 fps total: 2500 epoch: 185/200\n",
      "fps step: 3341 fps step and policy inference: 2563 fps total: 2472 epoch: 186/200\n",
      "fps step: 3371 fps step and policy inference: 2597 fps total: 2505 epoch: 187/200\n",
      "fps step: 3359 fps step and policy inference: 2585 fps total: 2495 epoch: 188/200\n",
      "fps step: 3383 fps step and policy inference: 2592 fps total: 2496 epoch: 189/200\n",
      "fps step: 3325 fps step and policy inference: 2552 fps total: 2453 epoch: 190/200\n",
      "fps step: 3322 fps step and policy inference: 2556 fps total: 2469 epoch: 191/200\n",
      "fps step: 3351 fps step and policy inference: 2577 fps total: 2487 epoch: 192/200\n",
      "fps step: 3332 fps step and policy inference: 2557 fps total: 2461 epoch: 193/200\n",
      "fps step: 3188 fps step and policy inference: 2453 fps total: 2364 epoch: 194/200\n",
      "fps step: 3225 fps step and policy inference: 2478 fps total: 2390 epoch: 195/200\n",
      "fps step: 3187 fps step and policy inference: 2446 fps total: 2363 epoch: 196/200\n",
      "fps step: 3190 fps step and policy inference: 2480 fps total: 2399 epoch: 197/200\n",
      "fps step: 3245 fps step and policy inference: 2491 fps total: 2400 epoch: 198/200\n",
      "fps step: 3205 fps step and policy inference: 2463 fps total: 2379 epoch: 199/200\n",
      "fps step: 3319 fps step and policy inference: 2554 fps total: 2461 epoch: 200/200\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/last_pendulumep200rew[-229.9454].pth'\n",
      "MAX EPOCHS NUM!\n"
     ]
    }
   ],
   "source": [
    "with open(config_name, 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    config['params']['config']['normalize_input'] = True\n",
    "    config['params']['config']['max_epochs'] = 200\n",
    "    config['params']['config']['full_experiment_name'] = 'pendulum_onnx'\n",
    "runner = Runner()\n",
    "runner.load(config)\n",
    "runner.run({\n",
    "    'train': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc130c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    '''\n",
    "    Main idea is to ignore outputs which we don't need from model\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self._model = model\n",
    "        \n",
    "        \n",
    "    def forward(self,input_dict):\n",
    "        input_dict['obs'] = self._model.norm_obs(input_dict['obs'])\n",
    "        '''\n",
    "        just model export doesn't work. Looks like onnx issue with torch distributions\n",
    "        thats why we are exporting only neural network\n",
    "        '''\n",
    "        #print(input_dict)\n",
    "        #output_dict = self._model.a2c_network(input_dict)\n",
    "        #input_dict['is_train'] = False\n",
    "        #return output_dict['logits'], output_dict['values']\n",
    "        return self._model.a2c_network(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40268292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observation_space': Box([-1. -1. -8.], [1. 1. 8.], (3,), float32), 'action_space': Box(-2.0, 2.0, (1,), float32), 'agents': 1, 'value_size': 1}\n",
      "build mlp: 3\n",
      "build mlp: 3\n",
      "RunningMeanStd:  (3,)\n",
      "=> loading checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "1 1\n",
      "(tensor([[0., 0., 0.]], device='cuda:0'),) (tensor([[0., 0., 0.]], device='cuda:0'),)\n",
      "(tensor([[0.4290]], device='cuda:0'), tensor([[-1.4877]], device='cuda:0'), tensor([[-0.9674]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/onnx/utils.py:359: UserWarning: Model has no forward function\n",
      "  warnings.warn(\"Model has no forward function\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%obs : Float(1, 3, strides=[3, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.sigma : Float(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.actor_mlp.0.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.actor_mlp.0.weight : Float(32, 3, strides=[3, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.actor_mlp.2.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.actor_mlp.2.weight : Float(32, 32, strides=[32, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.critic_mlp.0.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.critic_mlp.0.weight : Float(32, 3, strides=[3, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.critic_mlp.2.bias : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.critic_mlp.2.weight : Float(32, 32, strides=[32, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.value.bias : Float(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.value.weight : Float(1, 32, strides=[32, 1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.mu.bias : Float(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %model._model.a2c_network.mu.weight : Float(1, 32, strides=[32, 1], requires_grad=0, device=cuda:0),\n",
      "      %48 : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %51 : Float(3, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %54 : Long(2, strides=[1], requires_grad=0, device=cpu),\n",
      "      %57 : Long(2, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %18 : Float(1, 3, strides=[3, 1], device=cpu) = onnx::Sub(%obs, %48), scope: __module.model/__module.model._model.running_mean_std # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/running_mean_std.py:79:0\n",
      "  %y : Float(1, 3, strides=[3, 1], device=cpu) = onnx::Div(%18, %51), scope: __module.model/__module.model._model.running_mean_std # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/running_mean_std.py:79:0\n",
      "  %obs.1 : Float(1, 3, strides=[3, 1], device=cpu) = onnx::Clip[max=5., min=-5.](%y), scope: __module.model/__module.model._model.running_mean_std # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/running_mean_std.py:80:0\n",
      "  %input : Float(1, 3, device=cpu) = onnx::Reshape(%obs.1, %54), scope: __module.model/__module.model._model.a2c_network # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/network_builder.py:307:0\n",
      "  %input.3 : Float(1, 3, device=cpu) = onnx::Reshape(%obs.1, %57), scope: __module.model/__module.model._model.a2c_network # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/network_builder.py:310:0\n",
      "  %input.7 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input, %model._model.a2c_network.actor_mlp.0.weight, %model._model.a2c_network.actor_mlp.0.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.actor_mlp/__module.model._model.a2c_network.actor_mlp.0 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %input.11 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Elu[alpha=1.](%input.7), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.actor_mlp/__module.model._model.a2c_network.actor_mlp.1 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/functional.py:1534:0\n",
      "  %input.15 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.11, %model._model.a2c_network.actor_mlp.2.weight, %model._model.a2c_network.actor_mlp.2.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.actor_mlp/__module.model._model.a2c_network.actor_mlp.2 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %input.19 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Elu[alpha=1.](%input.15), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.actor_mlp/__module.model._model.a2c_network.actor_mlp.3 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/functional.py:1534:0\n",
      "  %input.23 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.3, %model._model.a2c_network.critic_mlp.0.weight, %model._model.a2c_network.critic_mlp.0.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.critic_mlp/__module.model._model.a2c_network.critic_mlp.0 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %input.27 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Elu[alpha=1.](%input.23), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.critic_mlp/__module.model._model.a2c_network.critic_mlp.1 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/functional.py:1534:0\n",
      "  %input.31 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.27, %model._model.a2c_network.critic_mlp.2.weight, %model._model.a2c_network.critic_mlp.2.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.critic_mlp/__module.model._model.a2c_network.critic_mlp.2 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %input.35 : Float(1, 32, strides=[32, 1], device=cpu) = onnx::Elu[alpha=1.](%input.31), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.critic_mlp/__module.model._model.a2c_network.critic_mlp.3 # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/functional.py:1534:0\n",
      "  %value : Float(1, 1, strides=[1, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.35, %model._model.a2c_network.value.weight, %model._model.a2c_network.value.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.value # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %mu : Float(1, 1, strides=[1, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.19, %model._model.a2c_network.mu.weight, %model._model.a2c_network.mu.bias), scope: __module.model/__module.model._model.a2c_network/__module.model._model.a2c_network.mu # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %45 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %46 : Float(1, 1, strides=[1, 1], device=cpu) = onnx::Mul(%mu, %45), scope: __module.model/__module.model._model.a2c_network # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/network_builder.py:375:0\n",
      "  %log_std : Float(1, 1, strides=[1, 1], requires_grad=1, device=cuda:0) = onnx::Add(%46, %model._model.a2c_network.sigma), scope: __module.model/__module.model._model.a2c_network # /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/algos_torch/network_builder.py:375:0\n",
      "  return (%mu, %log_std, %value)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = runner.create_player()\n",
    "agent.restore('runs/pendulum_onnx/nn/pendulum.pth')\n",
    "\n",
    "import rl_games.algos_torch.flatten as flatten\n",
    "inputs = {\n",
    "    'obs' : torch.zeros((1,) + agent.obs_shape).to(agent.device),\n",
    "    'rnn_states' : agent.states,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    adapter = flatten.TracingAdapter(ModelWrapper(agent.model), inputs,allow_non_tensor=True)\n",
    "    traced = torch.jit.trace(adapter, adapter.flattened_inputs,check_trace=False)\n",
    "    flattened_outputs = traced(*adapter.flattened_inputs)\n",
    "    print(flattened_outputs)\n",
    "    \n",
    "torch.onnx.export(traced, *adapter.flattened_inputs, \"pendulum.onnx\", verbose=True, input_names=['obs'], output_names=['mu','log_std', 'value'])\n",
    "\n",
    "onnx_model = onnx.load(\"pendulum.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c2e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.42947608]], dtype=float32), array([[-1.4877307]], dtype=float32), array([[-0.9669779]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "ort_model = ort.InferenceSession(\"pendulum.onnx\")\n",
    "\n",
    "outputs = ort_model.run(\n",
    "    None,\n",
    "    {\"obs\": np.zeros((1, 3)).astype(np.float32)},\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a41060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32c50a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5744312]\n",
      "[3.0435042]\n",
      "[3.3461144]\n",
      "[3.5552688]\n",
      "[3.6558933]\n",
      "[3.6372302]\n",
      "[3.5011947]\n",
      "[3.2604012]\n",
      "[2.9250076]\n",
      "[2.5060184]\n",
      "[2.0745935]\n",
      "[1.6998118]\n",
      "[1.5270209]\n",
      "[1.4712086]\n",
      "[1.2709275]\n",
      "[0.9568208]\n",
      "[0.6169096]\n",
      "[0.29001135]\n",
      "[-0.03854244]\n",
      "[-0.3977334]\n",
      "[-0.7772378]\n",
      "[-1.119332]\n",
      "[-1.3981546]\n",
      "[-1.5736771]\n",
      "[-1.6208159]\n",
      "[-1.5204344]\n",
      "[-1.2796079]\n",
      "[-0.9408687]\n",
      "[-0.573925]\n",
      "[-0.3071589]\n",
      "[-0.2773655]\n",
      "[-0.42557085]\n",
      "[-0.57951653]\n",
      "[-0.678273]\n",
      "[-0.7442626]\n",
      "[-0.79648864]\n",
      "[-0.84287536]\n",
      "[-0.90002215]\n",
      "[-0.9714671]\n",
      "[-1.0369996]\n",
      "[-1.0965557]\n",
      "[-1.1487722]\n",
      "[-1.1943798]\n",
      "[-1.2349553]\n",
      "[-1.2719566]\n",
      "[-1.3064971]\n",
      "[-1.3392601]\n",
      "[-1.370506]\n",
      "[-1.4000406]\n",
      "[-1.4271226]\n",
      "[-1.4528034]\n",
      "[-1.4788148]\n",
      "[-1.5048565]\n",
      "[-1.5302626]\n",
      "[-1.5538046]\n",
      "[-1.5733638]\n",
      "[-1.5853615]\n",
      "[-1.5838745]\n",
      "[-1.5625072]\n",
      "[-1.5170943]\n",
      "[-1.4410225]\n",
      "[-1.3232167]\n",
      "[-1.149319]\n",
      "[-0.9054007]\n",
      "[-0.5798164]\n",
      "[-0.15795323]\n",
      "[0.36813432]\n",
      "[0.99135995]\n",
      "[1.6637182]\n",
      "[2.2105649]\n",
      "[2.4795938]\n",
      "[2.4223804]\n",
      "[2.0225987]\n",
      "[1.3603784]\n",
      "[0.6703036]\n",
      "[0.2163481]\n",
      "[-0.11333267]\n",
      "[-0.39264995]\n",
      "[-0.66053885]\n",
      "[-0.96682656]\n",
      "[-1.3264623]\n",
      "[-1.6075215]\n",
      "[-1.7996343]\n",
      "[-1.9113573]\n",
      "[-1.9433638]\n",
      "[-1.9068688]\n",
      "[-1.8163718]\n",
      "[-1.6646932]\n",
      "[-1.4415878]\n",
      "[-1.1340694]\n",
      "[-0.7295957]\n",
      "[-0.218464]\n",
      "[0.39985967]\n",
      "[1.1055528]\n",
      "[1.7945336]\n",
      "[2.2655864]\n",
      "[2.4392104]\n",
      "[2.3010788]\n",
      "[1.7681403]\n",
      "[1.0675447]\n",
      "[0.46879023]\n",
      "[0.0816438]\n",
      "[-0.22047085]\n",
      "[-0.48858088]\n",
      "[-0.760235]\n",
      "[-1.0951033]\n",
      "[-1.4294529]\n",
      "[-1.6752062]\n",
      "[-1.8377326]\n",
      "[-1.9231378]\n",
      "[-1.931608]\n",
      "[-1.8802998]\n",
      "[-1.7754749]\n",
      "[-1.6084913]\n",
      "[-1.3676528]\n",
      "[-1.0402868]\n",
      "[-0.6136438]\n",
      "[-0.07962009]\n",
      "[0.5594418]\n",
      "[1.2747427]\n",
      "[1.9295666]\n",
      "[2.329244]\n",
      "[2.4566066]\n",
      "[2.2078047]\n",
      "[1.6153698]\n",
      "[0.8997827]\n",
      "[0.3646345]\n",
      "[0.00321095]\n",
      "[-0.2886421]\n",
      "[-0.5551417]\n",
      "[-0.83675253]\n",
      "[-1.1892244]\n",
      "[-1.5046401]\n",
      "[-1.7291512]\n",
      "[-1.8718741]\n",
      "[-1.9362724]\n",
      "[-1.925423]\n",
      "[-1.8588423]\n",
      "[-1.73554]\n",
      "[-1.5466712]\n",
      "[-1.2792398]\n",
      "[-0.92105955]\n",
      "[-0.4599412]\n",
      "[0.1095276]\n",
      "[0.7791266]\n",
      "[1.4987171]\n",
      "[2.0902956]\n",
      "[2.3846648]\n",
      "[2.429987]\n",
      "[2.0453866]\n",
      "[1.3884001]\n",
      "[0.6924383]\n",
      "[0.23050006]\n",
      "[-0.10240236]\n",
      "[-0.383111]\n",
      "[-0.65097845]\n",
      "[-0.9548418]\n",
      "[-1.3155899]\n",
      "[-1.6002251]\n",
      "[-1.7953666]\n",
      "[-1.9097544]\n",
      "[-1.9441419]\n",
      "[-1.9092855]\n",
      "[-1.820203]\n",
      "[-1.6700332]\n",
      "[-1.4486566]\n",
      "[-1.1430743]\n",
      "[-0.74077964]\n",
      "[-0.23190385]\n",
      "[0.38431823]\n",
      "[1.0887374]\n",
      "[1.7805345]\n",
      "[2.2582982]\n",
      "[2.436413]\n",
      "[2.3092582]\n",
      "[1.7825162]\n",
      "[1.0838125]\n",
      "[0.47902054]\n",
      "[0.08901085]\n",
      "[-0.21428177]\n",
      "[-0.48274386]\n",
      "[-0.75380933]\n",
      "[-1.0868914]\n",
      "[-1.4229212]\n",
      "[-1.6706434]\n",
      "[-1.8349141]\n",
      "[-1.9220406]\n",
      "[-1.9321581]\n",
      "[-1.8819853]\n",
      "[-1.7784805]\n",
      "[-1.6130127]\n",
      "[-1.3740189]\n",
      "[-1.0487747]\n",
      "[-0.6245246]\n",
      "[-0.09299803]\n",
      "[0.54382545]\n",
      "[1.2582642]\n",
      "[1.9168708]\n",
      "[2.3239658]\n",
      "[2.456024]\n",
      "-951.6801725663804 200\n"
     ]
    }
   ],
   "source": [
    "is_done = False\n",
    "env = agent.env\n",
    "obs = env.reset()\n",
    "#prev_screen = env.render(mode='rgb_array')\n",
    "#plt.imshow(prev_screen)\n",
    "total_reward = 0\n",
    "num_steps = 0\n",
    "while not is_done:\n",
    "    outputs = ort_model.run(None, {\"obs\": np.expand_dims(obs, axis=0).astype(np.float32)},)\n",
    "    action = outputs[0].squeeze(1)\n",
    "    print(action)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    num_steps += 1\n",
    "    is_done = done\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    #plt.imshow(screen)\n",
    "    #display.display(plt.gcf())    \n",
    "    #display.clear_output(wait=True)\n",
    "print(total_reward, num_steps)\n",
    "#ipythondisplay.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
