{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f833523c",
   "metadata": {},
   "source": [
    "**This is example of how to trace model with jit and export it to the onnx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d832d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "from rl_games.torch_runner import Runner\n",
    "import ray\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf09dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.12', ray_version='1.12.0', ray_commit='f18fc31c7562990955556899090f8e8656b48d2d', address_info={'node_ip_address': '10.2.168.57', 'raylet_ip_address': '10.2.168.57', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-09-16_13-18-13_562612_1202937/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-09-16_13-18-13_562612_1202937/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-09-16_13-18-13_562612_1202937', 'metrics_export_port': 49137, 'gcs_address': '10.2.168.57:46385', 'address': '10.2.168.57:46385', 'node_id': '1616c3c24137e3b7904ed818df91e989e9d6bfc948d684e8c4775004'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(object_store_memory=1024*1024*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8682b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = '../rl_games/configs/ppo_pendulum_torch.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.seed = 1663359495\n",
      "Started to train\n",
      "Exact experiment name requested from command line: pendulum_onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayWorker pid=1203304)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203304)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203308)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203308)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203305)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203305)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203307)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203307)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203310)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203310)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203303)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203303)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203309)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203309)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203306)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203306)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203446)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203446)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203468)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203468)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203456)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203456)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203503)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203503)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203433)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203433)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203492)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203492)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203532)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203532)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203513)\u001b[0m /home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayWorker pid=1203513)\u001b[0m   deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current training device: cuda:0\n",
      "build mlp: 3\n",
      "build mlp: 3\n",
      "RunningMeanStd:  (3,)\n",
      "fps step: 3240 fps step and policy inference: 1395 fps total: 1367 epoch: 1/500\n",
      "fps step: 3240 fps step and policy inference: 2521 fps total: 2438 epoch: 2/500\n",
      "fps step: 3243 fps step and policy inference: 2506 fps total: 2423 epoch: 3/500\n",
      "fps step: 3267 fps step and policy inference: 2518 fps total: 2435 epoch: 4/500\n",
      "fps step: 3277 fps step and policy inference: 2537 fps total: 2427 epoch: 5/500\n",
      "fps step: 3107 fps step and policy inference: 2397 fps total: 2314 epoch: 6/500\n",
      "fps step: 3281 fps step and policy inference: 2528 fps total: 2435 epoch: 7/500\n",
      "fps step: 3154 fps step and policy inference: 2440 fps total: 2346 epoch: 8/500\n",
      "fps step: 3084 fps step and policy inference: 2402 fps total: 2324 epoch: 9/500\n",
      "fps step: 3363 fps step and policy inference: 2575 fps total: 2480 epoch: 10/500\n",
      "saving next best rewards:  [-1216.8058]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3270 fps step and policy inference: 2529 fps total: 2442 epoch: 11/500\n",
      "saving next best rewards:  [-1204.9701]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3388 fps step and policy inference: 2599 fps total: 2507 epoch: 12/500\n",
      "fps step: 3410 fps step and policy inference: 2623 fps total: 2532 epoch: 13/500\n",
      "saving next best rewards:  [-1195.917]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3385 fps step and policy inference: 2598 fps total: 2506 epoch: 14/500\n",
      "fps step: 3337 fps step and policy inference: 2573 fps total: 2487 epoch: 15/500\n",
      "fps step: 3368 fps step and policy inference: 2598 fps total: 2510 epoch: 16/500\n",
      "fps step: 3386 fps step and policy inference: 2603 fps total: 2507 epoch: 17/500\n",
      "fps step: 3394 fps step and policy inference: 2613 fps total: 2521 epoch: 18/500\n",
      "saving next best rewards:  [-1182.0347]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3359 fps step and policy inference: 2584 fps total: 2491 epoch: 19/500\n",
      "saving next best rewards:  [-1164.7756]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3401 fps step and policy inference: 2625 fps total: 2535 epoch: 20/500\n",
      "fps step: 3419 fps step and policy inference: 2626 fps total: 2531 epoch: 21/500\n",
      "saving next best rewards:  [-1143.7142]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3366 fps step and policy inference: 2590 fps total: 2499 epoch: 22/500\n",
      "saving next best rewards:  [-1138.0548]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3333 fps step and policy inference: 2570 fps total: 2483 epoch: 23/500\n",
      "fps step: 3352 fps step and policy inference: 2584 fps total: 2494 epoch: 24/500\n",
      "saving next best rewards:  [-1116.0332]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3394 fps step and policy inference: 2612 fps total: 2521 epoch: 25/500\n",
      "saving next best rewards:  [-1113.6127]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3333 fps step and policy inference: 2569 fps total: 2481 epoch: 26/500\n",
      "fps step: 3381 fps step and policy inference: 2608 fps total: 2516 epoch: 27/500\n",
      "saving next best rewards:  [-1105.6077]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3446 fps step and policy inference: 2643 fps total: 2552 epoch: 28/500\n",
      "fps step: 3343 fps step and policy inference: 2574 fps total: 2485 epoch: 29/500\n",
      "fps step: 3392 fps step and policy inference: 2601 fps total: 2513 epoch: 30/500\n",
      "saving next best rewards:  [-1104.0862]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3413 fps step and policy inference: 2630 fps total: 2538 epoch: 31/500\n",
      "fps step: 3398 fps step and policy inference: 2621 fps total: 2531 epoch: 32/500\n",
      "saving next best rewards:  [-1100.5199]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3349 fps step and policy inference: 2581 fps total: 2491 epoch: 33/500\n",
      "fps step: 3458 fps step and policy inference: 2643 fps total: 2551 epoch: 34/500\n",
      "fps step: 3331 fps step and policy inference: 2583 fps total: 2486 epoch: 35/500\n",
      "fps step: 3404 fps step and policy inference: 2609 fps total: 2518 epoch: 36/500\n",
      "fps step: 3333 fps step and policy inference: 2574 fps total: 2487 epoch: 37/500\n",
      "fps step: 3344 fps step and policy inference: 2581 fps total: 2483 epoch: 38/500\n",
      "fps step: 3448 fps step and policy inference: 2639 fps total: 2545 epoch: 39/500\n",
      "fps step: 3314 fps step and policy inference: 2544 fps total: 2454 epoch: 40/500\n",
      "fps step: 3336 fps step and policy inference: 2579 fps total: 2490 epoch: 41/500\n",
      "saving next best rewards:  [-1092.214]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3356 fps step and policy inference: 2583 fps total: 2493 epoch: 42/500\n",
      "fps step: 3354 fps step and policy inference: 2592 fps total: 2506 epoch: 43/500\n",
      "saving next best rewards:  [-1060.1068]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3363 fps step and policy inference: 2585 fps total: 2496 epoch: 44/500\n",
      "saving next best rewards:  [-1022.80554]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3416 fps step and policy inference: 2626 fps total: 2537 epoch: 45/500\n",
      "fps step: 3403 fps step and policy inference: 2615 fps total: 2526 epoch: 46/500\n",
      "saving next best rewards:  [-983.7395]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3403 fps step and policy inference: 2609 fps total: 2518 epoch: 47/500\n",
      "saving next best rewards:  [-951.5135]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3325 fps step and policy inference: 2583 fps total: 2496 epoch: 48/500\n",
      "fps step: 3383 fps step and policy inference: 2591 fps total: 2500 epoch: 49/500\n",
      "saving next best rewards:  [-918.8817]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3227 fps step and policy inference: 2490 fps total: 2404 epoch: 50/500\n",
      "saving next best rewards:  [-892.5626]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3417 fps step and policy inference: 2629 fps total: 2535 epoch: 51/500\n",
      "fps step: 3244 fps step and policy inference: 2514 fps total: 2431 epoch: 52/500\n",
      "saving next best rewards:  [-862.10376]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3141 fps step and policy inference: 2449 fps total: 2367 epoch: 53/500\n",
      "fps step: 3326 fps step and policy inference: 2559 fps total: 2474 epoch: 54/500\n",
      "saving next best rewards:  [-814.13403]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3312 fps step and policy inference: 2557 fps total: 2472 epoch: 55/500\n",
      "saving next best rewards:  [-732.0134]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3452 fps step and policy inference: 2663 fps total: 2573 epoch: 56/500\n",
      "fps step: 3373 fps step and policy inference: 2600 fps total: 2511 epoch: 57/500\n",
      "saving next best rewards:  [-665.1217]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3287 fps step and policy inference: 2548 fps total: 2460 epoch: 58/500\n",
      "saving next best rewards:  [-608.48145]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3327 fps step and policy inference: 2561 fps total: 2475 epoch: 59/500\n",
      "fps step: 3299 fps step and policy inference: 2544 fps total: 2446 epoch: 60/500\n",
      "saving next best rewards:  [-550.9791]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3106 fps step and policy inference: 2383 fps total: 2300 epoch: 61/500\n",
      "saving next best rewards:  [-494.0699]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3157 fps step and policy inference: 2441 fps total: 2349 epoch: 62/500\n",
      "fps step: 3206 fps step and policy inference: 2467 fps total: 2376 epoch: 63/500\n",
      "saving next best rewards:  [-470.61105]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3168 fps step and policy inference: 2464 fps total: 2379 epoch: 64/500\n",
      "fps step: 3203 fps step and policy inference: 2481 fps total: 2399 epoch: 65/500\n",
      "saving next best rewards:  [-425.3805]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3231 fps step and policy inference: 2501 fps total: 2413 epoch: 66/500\n",
      "saving next best rewards:  [-394.32904]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps step: 3233 fps step and policy inference: 2490 fps total: 2403 epoch: 67/500\n",
      "fps step: 3340 fps step and policy inference: 2572 fps total: 2485 epoch: 68/500\n",
      "saving next best rewards:  [-361.25574]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3344 fps step and policy inference: 2572 fps total: 2479 epoch: 69/500\n",
      "saving next best rewards:  [-330.30405]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3224 fps step and policy inference: 2491 fps total: 2407 epoch: 70/500\n",
      "fps step: 3324 fps step and policy inference: 2557 fps total: 2468 epoch: 71/500\n",
      "saving next best rewards:  [-302.3561]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3310 fps step and policy inference: 2553 fps total: 2460 epoch: 72/500\n",
      "saving next best rewards:  [-281.5465]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3230 fps step and policy inference: 2477 fps total: 2398 epoch: 73/500\n",
      "fps step: 3279 fps step and policy inference: 2537 fps total: 2453 epoch: 74/500\n",
      "saving next best rewards:  [-278.8403]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3386 fps step and policy inference: 2598 fps total: 2506 epoch: 75/500\n",
      "saving next best rewards:  [-257.3744]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3200 fps step and policy inference: 2463 fps total: 2376 epoch: 76/500\n",
      "fps step: 3333 fps step and policy inference: 2562 fps total: 2471 epoch: 77/500\n",
      "saving next best rewards:  [-246.19066]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3341 fps step and policy inference: 2577 fps total: 2488 epoch: 78/500\n",
      "fps step: 3305 fps step and policy inference: 2545 fps total: 2453 epoch: 79/500\n",
      "saving next best rewards:  [-235.2545]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3268 fps step and policy inference: 2517 fps total: 2433 epoch: 80/500\n",
      "saving next best rewards:  [-228.49701]\n",
      "=> saving checkpoint 'runs/pendulum_onnx/nn/pendulum.pth'\n",
      "fps step: 3328 fps step and policy inference: 2564 fps total: 2471 epoch: 81/500\n",
      "fps step: 3355 fps step and policy inference: 2578 fps total: 2492 epoch: 82/500\n",
      "fps step: 3375 fps step and policy inference: 2615 fps total: 2523 epoch: 83/500\n",
      "fps step: 3358 fps step and policy inference: 2577 fps total: 2485 epoch: 84/500\n"
     ]
    }
   ],
   "source": [
    "with open(config_name, 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    config['params']['config']['normalize_input'] = True\n",
    "    config['params']['config']['max_epochs'] = 500\n",
    "    config['params']['config']['full_experiment_name'] = 'pendulum_onnx'\n",
    "    config['params']['config']['save_best_after'] = 10\n",
    "runner = Runner()\n",
    "runner.load(config)\n",
    "runner.run({\n",
    "    'train': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc130c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    '''\n",
    "    Main idea is to ignore outputs which we don't need from model\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self._model = model\n",
    "        \n",
    "        \n",
    "    def forward(self,input_dict):\n",
    "        input_dict['obs'] = self._model.norm_obs(input_dict['obs'])\n",
    "        '''\n",
    "        just model export doesn't work. Looks like onnx issue with torch distributions\n",
    "        thats why we are exporting only neural network\n",
    "        '''\n",
    "        #print(input_dict)\n",
    "        #output_dict = self._model.a2c_network(input_dict)\n",
    "        #input_dict['is_train'] = False\n",
    "        #return output_dict['logits'], output_dict['values']\n",
    "        return self._model.a2c_network(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40268292",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = runner.create_player()\n",
    "agent.restore('runs/pendulum_onnx/nn/pendulum.pth')\n",
    "\n",
    "import rl_games.algos_torch.flatten as flatten\n",
    "inputs = {\n",
    "    'obs' : torch.zeros((1,) + agent.obs_shape).to(agent.device),\n",
    "    'rnn_states' : agent.states,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    adapter = flatten.TracingAdapter(ModelWrapper(agent.model), inputs,allow_non_tensor=True)\n",
    "    traced = torch.jit.trace(adapter, adapter.flattened_inputs,check_trace=False)\n",
    "    flattened_outputs = traced(*adapter.flattened_inputs)\n",
    "    print(flattened_outputs)\n",
    "    \n",
    "torch.onnx.export(traced, *adapter.flattened_inputs, \"pendulum.onnx\", verbose=True, input_names=['obs'], output_names=['mu','log_std', 'value'])\n",
    "\n",
    "onnx_model = onnx.load(\"pendulum.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_model = ort.InferenceSession(\"pendulum.onnx\")\n",
    "\n",
    "outputs = ort_model.run(\n",
    "    None,\n",
    "    {\"obs\": np.zeros((1, 3)).astype(np.float32)},\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a41060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_done = False\n",
    "env = agent.env\n",
    "obs = env.reset()\n",
    "#prev_screen = env.render(mode='rgb_array')\n",
    "#plt.imshow(prev_screen)\n",
    "total_reward = 0\n",
    "num_steps = 0\n",
    "while not is_done:\n",
    "    outputs = ort_model.run(None, {\"obs\": np.expand_dims(obs, axis=0).astype(np.float32)},)\n",
    "    action = outputs[0].squeeze(1)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    num_steps += 1\n",
    "    is_done = done\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    #plt.imshow(screen)\n",
    "    #display.display(plt.gcf())    \n",
    "    #display.clear_output(wait=True)\n",
    "print(total_reward, num_steps)\n",
    "#ipythondisplay.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
