{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f833523c",
   "metadata": {},
   "source": [
    "**This is example of how to trace model with jit and export it to the onnx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d832d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "from rl_games.torch_runner import Runner\n",
    "import ray\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf09dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.12', ray_version='1.12.0', ray_commit='f18fc31c7562990955556899090f8e8656b48d2d', address_info={'node_ip_address': '10.2.168.57', 'raylet_ip_address': '10.2.168.57', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-09-16_13-05-39_286634_1198493/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-09-16_13-05-39_286634_1198493/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-09-16_13-05-39_286634_1198493', 'metrics_export_port': 50541, 'gcs_address': '10.2.168.57:55676', 'address': '10.2.168.57:55676', 'node_id': '90e2799f4b795ea1506755e4e3edf1b9fc7df173b9563c45bc412b9d'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(object_store_memory=1024*1024*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8682b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = '../rl_games/configs/ppo_cartpole.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.seed = 1663358741\n",
      "Started to train\n",
      "Exact experiment name requested from command line: cartpole_onnx\n",
      "current training device: cuda\n",
      "build mlp: 4\n",
      "build mlp: 4\n",
      "RunningMeanStd:  (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktorm/anaconda3/envs/warp39/lib/python3.9/site-packages/rl_games/common/experience.py:341: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.tensor_dict['actions'] = self._create_tensor_from_space(gym.spaces.Box(low=0, high=1,shape=self.actions_shape, dtype=np.long), obs_base_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps step: 3837 fps step and policy inference: 611 fps total: 537 epoch: 1/1000\n",
      "fps step: 3651 fps step and policy inference: 2651 fps total: 1677 epoch: 2/1000\n",
      "fps step: 3597 fps step and policy inference: 2596 fps total: 1658 epoch: 3/1000\n",
      "fps step: 3609 fps step and policy inference: 2601 fps total: 1652 epoch: 4/1000\n",
      "fps step: 3793 fps step and policy inference: 2693 fps total: 1686 epoch: 5/1000\n",
      "fps step: 3753 fps step and policy inference: 2714 fps total: 1682 epoch: 6/1000\n",
      "fps step: 3488 fps step and policy inference: 2510 fps total: 1650 epoch: 7/1000\n",
      "fps step: 3795 fps step and policy inference: 2716 fps total: 1692 epoch: 8/1000\n",
      "fps step: 3743 fps step and policy inference: 2707 fps total: 1701 epoch: 9/1000\n",
      "fps step: 3750 fps step and policy inference: 2720 fps total: 1708 epoch: 10/1000\n",
      "saving next best rewards:  [23.615122]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3862 fps step and policy inference: 2770 fps total: 1722 epoch: 11/1000\n",
      "fps step: 3904 fps step and policy inference: 2817 fps total: 1748 epoch: 12/1000\n",
      "saving next best rewards:  [24.036448]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3896 fps step and policy inference: 2840 fps total: 1760 epoch: 13/1000\n",
      "saving next best rewards:  [24.48986]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3812 fps step and policy inference: 2731 fps total: 1720 epoch: 14/1000\n",
      "saving next best rewards:  [24.600397]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3725 fps step and policy inference: 2669 fps total: 1696 epoch: 15/1000\n",
      "saving next best rewards:  [25.34234]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3750 fps step and policy inference: 2722 fps total: 1642 epoch: 16/1000\n",
      "saving next best rewards:  [25.38953]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3713 fps step and policy inference: 2732 fps total: 1727 epoch: 17/1000\n",
      "saving next best rewards:  [26.258585]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3670 fps step and policy inference: 2693 fps total: 1671 epoch: 18/1000\n",
      "saving next best rewards:  [28.23965]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3755 fps step and policy inference: 2708 fps total: 1674 epoch: 19/1000\n",
      "saving next best rewards:  [28.754326]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3645 fps step and policy inference: 2627 fps total: 1682 epoch: 20/1000\n",
      "saving next best rewards:  [30.433317]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3864 fps step and policy inference: 2755 fps total: 1722 epoch: 21/1000\n",
      "saving next best rewards:  [30.60856]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3836 fps step and policy inference: 2771 fps total: 1737 epoch: 22/1000\n",
      "fps step: 3802 fps step and policy inference: 2783 fps total: 1743 epoch: 23/1000\n",
      "saving next best rewards:  [31.465841]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3773 fps step and policy inference: 2725 fps total: 1588 epoch: 24/1000\n",
      "saving next best rewards:  [32.06866]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3471 fps step and policy inference: 2569 fps total: 1578 epoch: 25/1000\n",
      "saving next best rewards:  [34.91176]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3274 fps step and policy inference: 2386 fps total: 1479 epoch: 26/1000\n",
      "saving next best rewards:  [36.279526]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3218 fps step and policy inference: 2386 fps total: 1383 epoch: 27/1000\n",
      "saving next best rewards:  [36.798477]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 2853 fps step and policy inference: 2105 fps total: 1303 epoch: 28/1000\n",
      "saving next best rewards:  [39.514183]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 2736 fps step and policy inference: 2043 fps total: 1350 epoch: 29/1000\n",
      "saving next best rewards:  [42.057156]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3113 fps step and policy inference: 2338 fps total: 1571 epoch: 30/1000\n",
      "saving next best rewards:  [42.439514]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3283 fps step and policy inference: 2448 fps total: 1548 epoch: 31/1000\n",
      "saving next best rewards:  [44.949512]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3433 fps step and policy inference: 2558 fps total: 1550 epoch: 32/1000\n",
      "saving next best rewards:  [46.026497]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3484 fps step and policy inference: 2563 fps total: 1615 epoch: 33/1000\n",
      "saving next best rewards:  [52.17789]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 2530 fps step and policy inference: 1818 fps total: 1200 epoch: 34/1000\n",
      "saving next best rewards:  [55.331047]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3176 fps step and policy inference: 2348 fps total: 1439 epoch: 35/1000\n",
      "fps step: 3261 fps step and policy inference: 2429 fps total: 1478 epoch: 36/1000\n",
      "saving next best rewards:  [58.5612]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3160 fps step and policy inference: 2336 fps total: 1425 epoch: 37/1000\n",
      "saving next best rewards:  [61.34407]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3493 fps step and policy inference: 2601 fps total: 1615 epoch: 38/1000\n",
      "saving next best rewards:  [64.74424]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3774 fps step and policy inference: 2720 fps total: 1691 epoch: 39/1000\n",
      "saving next best rewards:  [67.60156]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3273 fps step and policy inference: 2399 fps total: 1466 epoch: 40/1000\n",
      "saving next best rewards:  [71.11689]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3181 fps step and policy inference: 2357 fps total: 1444 epoch: 41/1000\n",
      "fps step: 3737 fps step and policy inference: 2727 fps total: 1719 epoch: 42/1000\n",
      "saving next best rewards:  [75.77792]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3663 fps step and policy inference: 2693 fps total: 1694 epoch: 43/1000\n",
      "fps step: 3137 fps step and policy inference: 2223 fps total: 1491 epoch: 44/1000\n",
      "saving next best rewards:  [84.600044]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3724 fps step and policy inference: 2719 fps total: 1669 epoch: 45/1000\n",
      "saving next best rewards:  [87.55945]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3765 fps step and policy inference: 2785 fps total: 1725 epoch: 46/1000\n",
      "saving next best rewards:  [88.513855]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3832 fps step and policy inference: 2789 fps total: 1715 epoch: 47/1000\n",
      "saving next best rewards:  [89.25754]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3081 fps step and policy inference: 2333 fps total: 1560 epoch: 48/1000\n",
      "saving next best rewards:  [93.793846]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3849 fps step and policy inference: 2797 fps total: 1748 epoch: 49/1000\n",
      "fps step: 3767 fps step and policy inference: 2759 fps total: 1725 epoch: 50/1000\n",
      "saving next best rewards:  [94.35077]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 2570 fps step and policy inference: 1986 fps total: 1389 epoch: 51/1000\n",
      "fps step: 3841 fps step and policy inference: 2726 fps total: 1698 epoch: 52/1000\n",
      "saving next best rewards:  [95.06143]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3803 fps step and policy inference: 2775 fps total: 1699 epoch: 53/1000\n",
      "saving next best rewards:  [95.45188]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps step: 3226 fps step and policy inference: 2407 fps total: 1483 epoch: 54/1000\n",
      "saving next best rewards:  [95.85454]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3502 fps step and policy inference: 2593 fps total: 1583 epoch: 55/1000\n",
      "fps step: 3397 fps step and policy inference: 2531 fps total: 1661 epoch: 56/1000\n",
      "fps step: 3361 fps step and policy inference: 2485 fps total: 1603 epoch: 57/1000\n",
      "fps step: 3726 fps step and policy inference: 2728 fps total: 1707 epoch: 58/1000\n",
      "fps step: 3649 fps step and policy inference: 2648 fps total: 1687 epoch: 59/1000\n",
      "fps step: 3738 fps step and policy inference: 2725 fps total: 1726 epoch: 60/1000\n",
      "saving next best rewards:  [96.303566]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3818 fps step and policy inference: 2818 fps total: 1752 epoch: 61/1000\n",
      "fps step: 3581 fps step and policy inference: 2595 fps total: 1646 epoch: 62/1000\n",
      "fps step: 3717 fps step and policy inference: 2714 fps total: 1637 epoch: 63/1000\n",
      "saving next best rewards:  [97.881256]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3721 fps step and policy inference: 2729 fps total: 1684 epoch: 64/1000\n",
      "saving next best rewards:  [99.77463]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3658 fps step and policy inference: 2705 fps total: 1673 epoch: 65/1000\n",
      "saving next best rewards:  [100.53688]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3908 fps step and policy inference: 2830 fps total: 1638 epoch: 66/1000\n",
      "saving next best rewards:  [102.568115]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 2672 fps step and policy inference: 2055 fps total: 1342 epoch: 67/1000\n",
      "saving next best rewards:  [105.465164]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3265 fps step and policy inference: 2454 fps total: 1619 epoch: 68/1000\n",
      "saving next best rewards:  [107.179695]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3856 fps step and policy inference: 2806 fps total: 1722 epoch: 69/1000\n",
      "saving next best rewards:  [108.32533]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3791 fps step and policy inference: 2760 fps total: 1651 epoch: 70/1000\n",
      "fps step: 3002 fps step and policy inference: 2240 fps total: 1489 epoch: 71/1000\n",
      "fps step: 3527 fps step and policy inference: 2591 fps total: 1638 epoch: 72/1000\n",
      "fps step: 3833 fps step and policy inference: 2764 fps total: 1590 epoch: 73/1000\n",
      "fps step: 3556 fps step and policy inference: 2617 fps total: 1591 epoch: 74/1000\n",
      "fps step: 3461 fps step and policy inference: 2547 fps total: 1644 epoch: 75/1000\n",
      "fps step: 2192 fps step and policy inference: 1760 fps total: 1085 epoch: 76/1000\n",
      "fps step: 3566 fps step and policy inference: 2571 fps total: 1632 epoch: 77/1000\n",
      "fps step: 3016 fps step and policy inference: 2303 fps total: 1530 epoch: 78/1000\n",
      "fps step: 2846 fps step and policy inference: 2168 fps total: 1373 epoch: 79/1000\n",
      "fps step: 3748 fps step and policy inference: 2696 fps total: 1704 epoch: 80/1000\n",
      "fps step: 3728 fps step and policy inference: 2699 fps total: 1721 epoch: 81/1000\n",
      "fps step: 3829 fps step and policy inference: 2724 fps total: 1710 epoch: 82/1000\n",
      "saving next best rewards:  [109.646576]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3838 fps step and policy inference: 2782 fps total: 1738 epoch: 83/1000\n",
      "saving next best rewards:  [111.64189]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3942 fps step and policy inference: 2852 fps total: 1763 epoch: 84/1000\n",
      "saving next best rewards:  [113.1287]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3889 fps step and policy inference: 2818 fps total: 1737 epoch: 85/1000\n",
      "saving next best rewards:  [114.957344]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3819 fps step and policy inference: 2766 fps total: 1742 epoch: 86/1000\n",
      "saving next best rewards:  [118.03969]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n",
      "fps step: 3648 fps step and policy inference: 2686 fps total: 1651 epoch: 87/1000\n",
      "fps step: 3576 fps step and policy inference: 2634 fps total: 1624 epoch: 88/1000\n",
      "fps step: 3474 fps step and policy inference: 2547 fps total: 1531 epoch: 89/1000\n",
      "saving next best rewards:  [118.909966]\n",
      "=> saving checkpoint 'runs/cartpole_onnx/nn/cartpole_vel_info.pth'\n"
     ]
    }
   ],
   "source": [
    "with open(config_name, 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "    config['params']['config']['normalize_input'] = True\n",
    "    config['params']['config']['max_epochs'] = 1000\n",
    "    config['params']['config']['full_experiment_name'] = 'cartpole_onnx'\n",
    "runner = Runner()\n",
    "runner.load(config)\n",
    "runner.run({\n",
    "    'train': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc130c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    '''\n",
    "    Main idea is to ignore outputs which we don't need from model\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self._model = model\n",
    "        \n",
    "        \n",
    "    def forward(self,input_dict):\n",
    "        input_dict['obs'] = self._model.norm_obs(input_dict['obs'])\n",
    "        '''\n",
    "        just model export doesn't work. Looks like onnx issue with torch distributions\n",
    "        thats why we are exporting only neural network\n",
    "        '''\n",
    "        #print(input_dict)\n",
    "        #output_dict = self._model.a2c_network(input_dict)\n",
    "        #input_dict['is_train'] = False\n",
    "        #return output_dict['logits'], output_dict['values']\n",
    "        return self._model.a2c_network(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40268292",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = runner.create_player()\n",
    "agent.restore('runs/cartpole_onnx/nn/cartpole_vel_info.pth')\n",
    "\n",
    "import rl_games.algos_torch.flatten as flatten\n",
    "inputs = {\n",
    "    'obs' : torch.zeros((1,) + agent.obs_shape).to(agent.device),\n",
    "    'rnn_states' : agent.states,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    adapter = flatten.TracingAdapter(ModelWrapper(agent.model), inputs,allow_non_tensor=True)\n",
    "    traced = torch.jit.trace(adapter, adapter.flattened_inputs,check_trace=False)\n",
    "    flattened_outputs = traced(*adapter.flattened_inputs)\n",
    "    print(flattened_outputs)\n",
    "    \n",
    "torch.onnx.export(traced, *adapter.flattened_inputs, \"cartpole.onnx\", verbose=True, input_names=['obs'], output_names=['logits', 'value'])\n",
    "\n",
    "onnx_model = onnx.load(\"cartpole.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_model = ort.InferenceSession(\"cartpole.onnx\")\n",
    "\n",
    "outputs = ort_model.run(\n",
    "    None,\n",
    "    {\"obs\": np.zeros((1, 4)).astype(np.float32)},\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a41060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_done = False\n",
    "env = agent.env\n",
    "obs = env.reset()\n",
    "#prev_screen = env.render(mode='rgb_array')\n",
    "#plt.imshow(prev_screen)\n",
    "total_reward = 0\n",
    "num_steps = 0\n",
    "while not is_done:\n",
    "    outputs = ort_model.run(None, {\"obs\": np.expand_dims(obs, axis=0).astype(np.float32)},)\n",
    "    action = np.argmax(outputs[0])\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    num_steps += 1\n",
    "    is_done = done\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    #plt.imshow(screen)\n",
    "    #display.display(plt.gcf())    \n",
    "    #display.clear_output(wait=True)\n",
    "print(total_reward, num_steps)\n",
    "#ipythondisplay.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
